---
title: "Measuring growth rate and reproduction number for SARS-CoV-2 variants"
output: 
  html_document:
    theme: sandstone
date: "2025-03-10"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(cols4all)
library(here)
library(gridExtra)
library(scales)
```

### Question 1

#### 1.1

**Download the dataset: download Genomes_per_week_in_England.csv from Canvas. This includes weekly counts of virus samples per lineage over time across England collected as part of Sanger Institute COG-UK.**

```{r downloadDataset}

# Import COG-UK daily genomic sequence data
COGdata <- read.csv(here("data", "Genomes_per_week_in_England.csv"))

# Check the input format and display the first few rows of the data
head(COGdata)
```

#### 1.2

**Classify major lineages: identify the following variants as major lineages: B.1.1.7 (Alpha), B.1.617.2 (Delta), BA.1, BA.2, BA.2.75, BA.4, BA.5, BA.5.3 (BQ.1), and XBB. Group all other lineages into a single category labelled as Other.**

```{r setMajorLineages}

# Specify the major lineages
major_lineages <- c("B.1.1.7", "B.1.617.2", "BA.1", "BA.2", "BA.2.75", "BA.4", "BA.5", "BA.5.3", "XBB")

# Cleaning the data
COGclean <- COGdata %>%
  # Ensure collection_date is in Date format
  mutate(date = as.Date(date)) %>%
  # Grouping all non-major lineages as 'other' 
  mutate(lineage = ifelse(lineage %in% major_lineages, lineage, "Other")) %>%
  # Rename columns for clarity
  {colnames(.) <- c("collection_date", "major_lineage", "lineage_count"); .}

# Check the format of the columns after cleaning the data and displaying the first few rows of the data

head(COGclean)
```

#### 1.3

**Visualise the data: generate a stacked area plot showing the total counts of each major lineage over time. Generate another stacked area plot showing the frequencies (proportions) of each major lineage over time.**

```{r frequencyData}

# Calculate total counts per date
total_COG_counts <- aggregate(COGclean$lineage_count, by = list(collection_date = COGclean$collection_date), FUN = sum)
colnames(total_COG_counts) <- c("collection_date", "total_count")

# Merge total counts back into the lineage summary
COGclean <- merge(COGclean, total_COG_counts, by = "collection_date")

# Calculate frequencies
COGclean$lineage_frequency <- COGclean$lineage_count / COGclean$total_count

# Display the first few rows of the new data frame
head(COGclean)
```



```{r stackedPlots}

# Set a colour blind friendly colour palette
palette <- c4a("safe",10)

# Make stacked area plot for total counts of each major lineage
countPlot <- ggplot(COGclean, aes(x = collection_date, y = lineage_count, fill = major_lineage)) +
    geom_area(position = "fill") +  # Create a stacked area plot
    scale_fill_manual(values = palette) +  # Apply the custom palette
    labs(
      title = "Total counts of major lineages over time",
      x = "Collection date",
      y = "Total count",
      fill = "Major lineage"
    ) +
    theme_minimal()



# Make stacked area plot for frequencies of each major lineage
frequencyPlot <- ggplot(COGclean, aes(x = collection_date, y = lineage_frequency, fill = major_lineage)) +
    geom_area(position = "fill") +  # Create a stacked area plot
    scale_fill_manual(values = palette) +  # Apply the custom palette
    labs(
      title = "Frequency of major lineages over time",
      x = "Collection date",
      y = "Proportion",
      fill = "Major lineage"
    ) +
    theme_minimal()

# Printing the two plots
grid.arrange(countPlot, frequencyPlot, ncol=2, nrow =1)
```

### Question 2

#### 2.1

**Visualise the COG-UK and ONS-CIS data for BA.2: plot the frequency trajectory for the BA.2 variant using both the Sanger dataset (weekly counts) and the ONS-CIS dataset (10-day bin counts from the practical).**

```{r ONSdataSetup}

# Import ONS-CIS daily genomic sequence data
ONSdata <- read.csv("https://raw.githubusercontent.com/mg878/variant_fitness_practical/main/lineage_data.csv")

# Ensure collection_date is in Date format
ONSdata$collection_date <- as.Date(ONSdata$collection_date)

# Create new data frame 
ONSsummary <- aggregate(
  ONSdata$major_lineage,
  by = list(collection_date = ONSdata$collection_date, major_lineage = ONSdata$major_lineage),
  FUN = length
)

# Rename columns for clarity
colnames(ONSsummary) <- c("collection_date", "major_lineage", "lineage_count")

# Calculate total counts per date
total_ONS_counts <- aggregate(ONSsummary$lineage_count, by = list(collection_date = ONSsummary$collection_date), FUN = sum)
colnames(total_ONS_counts) <- c("collection_date", "total_count")

# Merge total counts back into the lineage summary
ONSsummary <- merge(ONSsummary, total_ONS_counts, by = "collection_date")

# Calculate frequencies
ONSsummary$lineage_frequency <- ONSsummary$lineage_count / ONSsummary$total_count

# Display the first few rows of the new data frame
head(ONSsummary)
```

```{r ONS10dayBins}
# Aggregate lineage frequencies into 10-day bins
# Converts the Date values into numeric format, where each date is represented as the number of days since 1970-01-01 (the Unix epoch)
ONSsummary$collection_date_bin <- as.Date(
  floor(as.numeric(as.Date(ONSsummary$collection_date)) / 10) * 10, origin = "1970-01-01"
)

# Aggregate lineage counts for each 10-day bin
ONS_summary_binned <- aggregate(
  lineage_count ~ collection_date_bin + major_lineage,
  data = ONSsummary,
  FUN = sum
)

# Calculate total counts within each bin
total_ONS_counts <- aggregate(
  lineage_count ~ collection_date_bin,
  data = ONS_summary_binned,
  FUN = sum
)

# Rename columns for clarity
colnames(total_ONS_counts) <- c("collection_date_bin", "total_count") 

# Merge total counts back into the binned data
ONS_summary_binned <- merge(ONS_summary_binned, total_ONS_counts, by = "collection_date_bin")

# Recalculate frequencies
ONS_summary_binned$lineage_frequency <- ONS_summary_binned$lineage_count / ONS_summary_binned$total_count

# Preview the binned data
head(ONS_summary_binned)

```

```{r BA.2frequencyTrajectory, fig.height=3}

# Filter COG data for BA.2
COG_daily_trajectories <- subset(
  COGclean,
  major_lineage %in% c("BA.2")
)

# Filter ONS data for BA.2
ONS_daily_trajectories <-subset(
  ONS_summary_binned,
  major_lineage %in% c("BA.2")
)


# COG Data BA.2 frequency trajectory plot
COGBA2plot <- ggplot(COG_daily_trajectories, aes(x = collection_date, y = lineage_frequency)) +
  geom_line(linewidth = 1, color = "blue") +  # Connect the points with lines
  geom_point(size = 2, alpha = 0.7) +  # Add points for daily frequencies
  labs(
    title = "COG Frequency trajectories of BA.2",
    x = "Collection date",
    y = "Proportion",
  ) +
  theme_minimal()

# ONS data BA.2 frequency trajectory plot
ONSBA2plot <- ggplot(ONS_daily_trajectories, aes(x = collection_date_bin, y = lineage_frequency)) +
  geom_line(linewidth = 1, color = "red") +  # Connect the points with lines
  geom_point(size = 2, alpha = 0.7) +  # Add points for daily frequencies
  labs(
    title = "COG Frequency trajectories of BA.2",
    x = "Collection date",
    y = "Proportion",
  ) +
  theme_minimal()

# ONS and COG data on the same plot
BA2ONSCOGplot <- ggplot(COG_daily_trajectories, aes(x = collection_date_bin, y = lineage_frequency)) +
  geom_line(data = COG_daily_trajectories, linewidth = 1, aes(color = "COG Data", x = collection_date )) + 
  geom_line(data = ONS_daily_trajectories, linewidth = 1, aes(color = "ONS Data")) +
  scale_color_manual(name = "Dataset", 
                     values = c("COG Data" = "blue", "ONS Data" = "red")) +
  labs(
    title = "Frequency trajectories of BA.2",
    x = "Collection date",
    y = "Proportion",
    color = "Dataset") +
  theme_minimal() +
  theme(legend.position = c(0.225, 0.75),
        legend.background = element_rect(fill = "white", color = "black"))
  
ZoomedBA2ONSCOGplot <- ggplot(COG_daily_trajectories, aes(x = collection_date_bin, y = lineage_frequency)) +
  geom_line(data = COG_daily_trajectories, linewidth = 1, aes(color = "COG Data" , x = collection_date)) + 
  geom_line(data = ONS_daily_trajectories, linewidth = 1, aes(color = "ONS Data")) +
  scale_color_manual(name = "Dataset", 
                     values = c("COG Data" = "blue", "ONS Data" = "red")) +
  labs(
    title = "Frequency trajectories of BA.2",
    x = "Collection date",
    y = "Proportion",
    color = "Dataset") +
  theme_minimal() +
  theme(legend.position = c(0.225, 0.75),
        legend.background = element_rect(fill = "white", color = "black"))+
  coord_cartesian(xlim = as.Date(c("2022-01-01", "2022-06-30")))

# Printing the plots 
grid.arrange(COGBA2plot, ONSBA2plot, BA2ONSCOGplot, ZoomedBA2ONSCOGplot, ncol=2, nrow =2)

```

#### 2.2

**Analysis: compare the two trajectories. Is there a difference in the timing of BA.2â€™s rise and when it reaches fixation? Reflect on potential reasons for these differences (sampling strategies and geographical or temporal biases in data collection)?**

The two trajectories are almost identical, with BA.2 first appearing at the start of 2022, rising to fixation around 3 months later. The ONS peak for BA.2 is slightly ahead of the COG data peak. One reason for this could be that the ONS data was collected from all individuals, whether symptomatic or not, whilst the COG data was collected from patients. This means that the ONS data would have picked up cases before they became symptomatic, whilst the COG data may have a small delay due to the time taken for cases to become symptomatic.

### Question 3

**Using the Sanger dataset, determine which variantâ€”B.1.617.2, BA.1, or BA.2â€”reached fixation the fastest and exhibited the highest selective advantage under a logistic growth model. Use weekly counts to measure the selective advantage (ğ‘ )**

```{r logisticGrowthFunction}
## logistic growth function

## do i need this defining parameters section? if so need to determine what they should be!!
# Define parameters
N <- 1e5          # Population size
s <- 0.1          # Selection coefficient
f0 <- 1 / N       # Initial frequency of the variant
tmax <- 200       # Maximum number of generations
t <- seq(0, tmax, by = 1) # Time in generations 

# Logistic growth equation
logistic_growth <- function(t, s, f0) {
  (f0 * exp(s * t)) / (1 + f0 * (exp(s * t) - 1))
}

```

```{r selectiveAdvantageFunction}
# Setting up the selectiveAdvantage function
selectiveAdvantage <- function(lineage, title1, title2, startDate, endDate, colour) {
  
  variant_data <- subset(COGclean, major_lineage == lineage)
  
  dailyFrequencyPlot <- ggplot(variant_data, aes(x = collection_date, 
                                                 y = lineage_frequency)) +
    geom_line(color = colour, linewidth = 1) +  # Static color assigned outside aes()
    geom_point(size = 2, alpha = 0.7, color = colour) +  # Static color for points
    labs(
      title = title1,
      x = "Collection Date",
      y = "Proportion"
    ) +
    theme_minimal()
  
  
  # Subset data to only include the increasing trajectory for Delta
  variant_growth_phase <- variant_data[
    variant_data$collection_date >= as.Date(startDate) & variant_data$collection_date <= as.Date(endDate),
  ]
  
  # Fit the logistic model using nls
  nls_fit <- nls(
    lineage_frequency ~ logistic_growth(as.numeric(collection_date - min(collection_date)), s, f0),
    data = variant_growth_phase,
    start = list(s = 0.1, f0 = min(variant_growth_phase$lineage_frequency))  # Initial guesses
  )
  
  # Extract fitted growth rate
  growth_rate <- coef(nls_fit)["s"]
  
  # Generate a smooth sequence of dates for plotting the logistic curve
  smooth_dates <- seq(min(variant_growth_phase$collection_date),
                      max(variant_growth_phase$collection_date), by = "1 day")
  
  # Calculate predicted frequencies for smooth (continuous) dates 
  smooth_predictions <- data.frame(
    collection_date = smooth_dates,
    predicted_frequency = logistic_growth(as.numeric(smooth_dates - min(variant_growth_phase$collection_date)),
                                          coef(nls_fit)["s"], coef(nls_fit)["f0"])
  )
  
  # Visualise the actual data points and the smooth logistic fit
  logisticFitPlot <- ggplot(variant_growth_phase, aes(x = collection_date)) +
    geom_point(aes(y = lineage_frequency), color = "black", size = 2, alpha = 0.7) +
    geom_line(data = smooth_predictions, aes(x = collection_date, y = predicted_frequency),
              color = colour, size = 1) +
    annotate(
      "text", 
      x = min(variant_growth_phase$collection_date, na.rm = TRUE) + 0.2 * 
        (max(variant_growth_phase$collection_date, na.rm = TRUE) - 
         min(variant_growth_phase$collection_date, na.rm = TRUE)), 
      y = 0.8, 
      label = paste0("s= ", round(growth_rate, 4)), 
      color = colour, 
      size = 5
    ) +
    labs(
      title = title2,
      x = "Collection date",
      y = "Frequency"
    ) +
    theme_minimal()
  
  grid.arrange(dailyFrequencyPlot, logisticFitPlot, ncol=2, nrow =1)
}
```

```{r deltaSelectiveAdvantage}

selectiveAdvantage("B.1.617.2", 
                   "Daily Frequency Trajectories of B.1.617.2", 
                   "Logistic growth fit for B.1.617.2 variant frequency",
                   "2021-04-23", 
                   "2021-07-12",
                   "#CC6677")
```

```{r BA1selectiveAdvantage}
selectiveAdvantage("BA.1", 
                   "Daily Frequency Trajectories of BA.1", 
                   "Logistic growth fit for BA.1 variant frequency",
                   "2021-11-25", 
                   "2022-01-10",
                   "#DDCC77")
```

```{r BA2selectiveAdvantage}
selectiveAdvantage("BA.2", 
                   "Daily Frequency Trajectories of BA.2", 
                   "Logistic growth fit for BA.2 variant frequency",
                   "2022-01-01", 
                   "2022-04-20",
                   "#117733")
```

### Question 4

#### 4.1

**Load the dataset: download and load delta-d2.rds from Canvas. This dataset contains an anonymised line list of individuals with a sequenced Delta sample from various regions in England, collected as part of the COG-UK. (hint: remove rows for which there is no associated phecname subset(data, phecname != ""))**

```{r loadDeltaDataset}

# Loading in the dataset
deltaDataRaw <- readRDS(here("data", "delta-d2.rds"))

# Cleaning the data
deltaDataClean <- deltaDataRaw %>%
  # Rename columns for clarity
  rename(
    collection_date = date,
    region = phecname,
    delta = Delta) %>%
  # Ensure collection_date is in Date format
  mutate(collection_date = as.Date(collection_date)) %>%
  # Remove rows with no associated region 
  filter(region != "") %>%
  # Remove time column
  select(-time)
```

#### 4.2
**Analyse and visualise the data: (i) plot Delta frequencies by region; for each region, plot the frequency of Delta over time. Use distinct colours or facets to differentiate between regions. (ii) Fit logistic growth for each region; for each region, fit a logistic growth model to the frequency data. Overlay the logistic growth curves onto the frequency trajectories for each region.**

```{r calculatingCountData}
# Create new data frame 
deltaSummary <- aggregate(
  deltaDataClean$delta,
  by = list(
    collection_date = deltaDataClean$collection_date,
    delta = deltaDataClean$delta,
    region = deltaDataClean$region),
  FUN = length
)

# Rename columns for clarity
colnames(deltaSummary) <- c("collection_date", "delta", "region", "lineage_count")

# Calculate total counts per date
total_delta_counts <- aggregate(
  deltaSummary$lineage_count, by = list(
    collection_date = deltaSummary$collection_date,
    region = deltaSummary$region), 
  FUN = sum)
colnames(total_delta_counts) <- c("collection_date", "region", "total_count")

# Merge total counts back into the lineage summary
deltaSummary <- merge(deltaSummary, total_delta_counts, by = c("collection_date", "region"))

# Calculate frequencies
deltaSummary$lineage_frequency <- deltaSummary$lineage_count / deltaSummary$total_count

# Display the first few rows of the new data frame
head(deltaSummary)
```

```{r binnedData}

# Aggregate lineage frequencies into 7-day bins
# Converts the Date values into numeric format, where each date is represented as the number of days since 1970-01-01 (the Unix epoch)
deltaSummary$collection_date_bin <- as.Date(
  floor(as.numeric(as.Date(deltaSummary$collection_date)) / 7) * 7, origin = "1970-01-01"
)

# Aggregate lineage counts for each 7-day bin
deltaSummaryBinned <- aggregate(
  lineage_count ~ collection_date_bin + delta + region,
  data = deltaSummary,
  FUN = sum
)

# Calculate total counts within each bin
totalDeltaBinCounts <- aggregate(
  lineage_count ~ collection_date_bin + region,
  data = deltaSummaryBinned,
  FUN = sum
)
colnames(totalDeltaBinCounts) <- c("collection_date_bin", "region", "total_count")  # Rename for clarity

# Merge total counts back into the binned data
deltaSummaryBinned <- merge(deltaSummaryBinned, totalDeltaBinCounts, by = c("collection_date_bin", "region"))

# Recalculate frequencies
deltaSummaryBinned$lineage_frequency <- deltaSummaryBinned$lineage_count / deltaSummaryBinned$total_count

# Preview the binned data
head(deltaSummaryBinned)
```

```{r logisticModel}
# Subsetting the data for Delta positive tests
deltaPositive <- subset(deltaSummaryBinned, delta == TRUE)

# List of unique regions
regions <- unique(deltaPositive$region)

# Empty list to store model parameters for Q4.3
region_parameters <- data.frame(region = character(), f0 = numeric(), s = numeric(), stringsAsFactors = FALSE)

# Empty list to store logistic fit results for each region
all_smooth_predictions <- list()

# Loop over each region
for (r in regions) {
  
  # Subset data for the current region and the selected date range
  variant_growth_phase <- subset(deltaPositive, 
                                 region == r)

  # Fit the logistic model using nls
  nls_fit <- nls(
    lineage_frequency ~ logistic_growth(as.numeric(collection_date_bin - min(collection_date_bin)), s, f0),
    data = variant_growth_phase,
    start = list(s = 0.1, f0 = min(variant_growth_phase$lineage_frequency))
  )
  
   # Extract parameters
  growth_rate <- coef(nls_fit)["s"]
  initial_frequency <- coef(nls_fit)["f0"]
  
  # Store the parameters in the dataframe
  region_parameters <- rbind(region_parameters, 
                             data.frame(region = r, 
                                        f0 = initial_frequency,
                                        s = growth_rate))
  
  # Generate a smooth sequence of dates for plotting the logistic curve
smooth_dates <- seq(min(variant_growth_phase$collection_date_bin),
                    max(variant_growth_phase$collection_date_bin), by = "1 day")
  
  
  # Calculate predicted frequencies for smooth (continuous) dates 
  smooth_predictions <- data.frame(
    collection_date_bin = smooth_dates,
    predicted_frequency = logistic_growth(as.numeric(smooth_dates - min(variant_growth_phase$collection_date_bin)),
                                          coef(nls_fit)["s"], coef(nls_fit)["f0"]),
    region = r
  )
  
 
  # Store predictions for this region
  all_smooth_predictions[[r]] <- smooth_predictions
  
  
}

# Combine all regional predictions into one data frame
all_smooth_predictions <- do.call(rbind, all_smooth_predictions)

# Plot data
ggplot(deltaPositive, aes(x = collection_date_bin, y = lineage_frequency)) +
  geom_line(data = all_smooth_predictions, aes(y = predicted_frequency, color = "Logistic Model"), size = 1) +
  geom_line(aes(color = "Frequencies")) +
  facet_wrap(~region) +
    scale_color_manual(name = "Legend", 
                       values = c("Frequencies" = "black", "Logistic Model" = "red")) +
  labs(title = "Delta Frequencies and  by Region", 
       x = "Collection date", 
       y = "Frequency") +
  theme_minimal()


#i have messed this up somewhere trying to add in a part where it extracts s and f0
```

#### 4.3
**Interpretation: (i) Identify the region with the fastest Delta outbreak; based on your analysis, determine which region had the most rapidly growing outbreak of Delta (highest ğ‘ ). Identify the region where Delta had the earliest rise in frequencies (highest ğ‘“0). Discuss why the timing of Deltaâ€™s emergence differed between regions. (ii) Could Deltaâ€™s growth across regions be associated with a founder effect? Explain what a founder effect is and evaluate whether the observed data supports or refutes this hypothesis.**

```{r}

# Plotting s per region
sPlot <- ggplot(region_parameters, aes(x = region, y = s, fill = region)) + 
  geom_col() +
  scale_fill_manual(values = palette) +  # Apply the custom palette
    labs(
      title = "Growth rate(s) per region",
      x = "Region",
      y = "s") +
  theme_minimal() +
  theme(legend.position = "none") +
  scale_x_discrete(labels = label_wrap(10))

# Plotting f0 per region
f0Plot <- ggplot(region_parameters, aes(x = region, y = f0, fill = region)) + 
  geom_col() +
  scale_fill_manual(values = palette) +  # Apply the custom palette
    labs(
      title = "Growth rate(s) per region",
      x = "Region",
      y = "f0") +
  theme_minimal() +
  theme(legend.position = "none") +
  scale_x_discrete(labels = label_wrap(10))

# Displaying the plots 
grid.arrange(sPlot, f0Plot, ncol=2, nrow =1)

```



### Question 5

#### 5.1

**Estimate the true incidence of Delta: Up to this point, we have relied on the number of PCR-positive tests sent to the Sanger Institute for sequencing to estimate the growth rate of variants. However, does this approach accurately reflect the true incidence of Delta infections in England? Explain how it is different from the incidence.**

yay lots of brain thoughts !

**To obtain a more representative estimate of the true number of Delta infections, multiply the proportion of Delta sequences in England (from the Sanger dataset) by the daily (7-day averaged) COVID-19 case counts in England provided in the daily-new-confirmed-covid-19-cases.csv dataset on Canvas.**

**Note that while the daily COVID-19 case counts are reported on a daily basis, the proportion of Delta sequences from the Sanger dataset is calculated weekly. For this task, use the same weekly proportion of Delta for every day within each 7-day interval of the daily case counts.**

**Plot estimated daily cases of Delta and weekly number of Delta sequences from Sanger. Reflect on why the two counts are different from each other.**

```{r calculateAndPlotIncidence}
library(tidyverse)

# Loading in the data
dailyCases <- read.csv(here("data", "daily-new-confirmed-covid-19-cases.csv"))

# Cleaning dailyCases so it can be merged with COGclean
dailyCases <- dailyCases %>%
  # filter out dates outside of the range of the COG dataset
  filter(date >= as.Date("2020-09-05") & date <= as.Date("2023-02-11")) %>% 
  # Rename columns for clarity 
  rename(cases = cases_sevendayaveraged) %>% 
  # Aggregate lineage frequencies into 7-day bins
  mutate(
    date = as.Date(date),
    weeklyDate = as.Date(floor((as.numeric(date) - as.numeric(as.Date("2020-09-05"))) / 7) * 7 + as.numeric(as.Date("2020-09-05")), 
    origin = "1970-01-01"))
 
# Filtering COGclean, merging it with dailyCases and calculate deltaIncidence
dailyIncidence <- COGclean %>% 
  # Filtering the dataset to only include Delta
  filter(major_lineage == "B.1.617.2") %>% 
  # Removing unneeded columns
  select(-c(major_lineage, total_count)) %>% 
  # Renaming column for consistency with the dailyCases dataset
  rename(weeklyDate = collection_date) %>% 
  # Merging this dataset with dailyCases
  left_join(dailyCases, by = "weeklyDate") %>% 
  # Calculating daily incidence of Delta 
  mutate(deltaIncidence = lineage_frequency * cases)

# Plotting estimated daily cases, and weekly number of delta sequences 
ggplot(dailyIncidence, aes(x = weeklyDate)) +
  geom_line(aes(y = lineage_count, # Plots weekly no. delta seqeunces
                color = "Sanger Sequences")) + 
  geom_line(aes(x = date, # Plots estimated daily delta cases
                y = deltaIncidence, 
                color = "Estimated Daily Cases")) +
  scale_x_date(limits = c(as.Date("2021-04-01"), as.Date("2022-04-01"))) +
  scale_color_manual( # Adds the legend 
    name = "Legend", 
    values = c(
      "Sanger Sequences" = "blue",
      "Estimated Daily Cases" = "red")) +
  labs( # Labels the axes and title
    title = "Lineage Count and Delta Incidence Over Time",
    x = "Date",
    y = "Count"
  ) +
  theme_minimal() +
  theme(legend.position = c(0.1, 0.9), # Adjusts the position of the legend 
        legend.justification = c(0.2, 0.7))



```

#### 5.2

**Measure ğ‘…ğ‘¡: Using the estimated daily Delta case counts, calculate the time-varying reproduction number (ğ‘…ğ‘¡) using the same method as in the practical (hint: use this time range: â€œ2021-04-23â€ to â€œ2021-11-01â€ for measurement).**

**Compare your ğ‘…ğ‘¡ estimate to the one calculated during the practical using the ONS-CIS dataset.**

**Reflect on whether the two estimates differ significantly. Which estimate do you consider more reliable, and why? (hint: consider factors such as the sampling strategy used by the different datasets and the representativeness of the sequencing data for actual infections.)**

